{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Importación de librerías Requeridas\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>...</th>\n",
       "      <th>contact_telephone</th>\n",
       "      <th>contact_unknown</th>\n",
       "      <th>month_aug</th>\n",
       "      <th>month_feb</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>poutcome_unknown</th>\n",
       "      <th>y_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>2143</td>\n",
       "      <td>5</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>1506</td>\n",
       "      <td>5</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41114</th>\n",
       "      <td>23</td>\n",
       "      <td>113</td>\n",
       "      <td>17</td>\n",
       "      <td>266</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41115</th>\n",
       "      <td>73</td>\n",
       "      <td>2850</td>\n",
       "      <td>17</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41116</th>\n",
       "      <td>25</td>\n",
       "      <td>505</td>\n",
       "      <td>17</td>\n",
       "      <td>386</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41117</th>\n",
       "      <td>71</td>\n",
       "      <td>1729</td>\n",
       "      <td>17</td>\n",
       "      <td>456</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41118</th>\n",
       "      <td>57</td>\n",
       "      <td>668</td>\n",
       "      <td>17</td>\n",
       "      <td>508</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41119 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  balance  day  duration  campaign  pdays  previous  \\\n",
       "0       58     2143    5       261         1     -1         0   \n",
       "1       44       29    5       151         1     -1         0   \n",
       "2       33        2    5        76         1     -1         0   \n",
       "3       47     1506    5        92         1     -1         0   \n",
       "4       33        1    5       198         1     -1         0   \n",
       "...    ...      ...  ...       ...       ...    ...       ...   \n",
       "41114   23      113   17       266         1     -1         0   \n",
       "41115   73     2850   17       300         1     40         8   \n",
       "41116   25      505   17       386         2     -1         0   \n",
       "41117   71     1729   17       456         2     -1         0   \n",
       "41118   57      668   17       508         4     -1         0   \n",
       "\n",
       "       job_blue-collar  job_management  job_retired  ...  contact_telephone  \\\n",
       "0                    0               1            0  ...                  0   \n",
       "1                    0               0            0  ...                  0   \n",
       "2                    0               0            0  ...                  0   \n",
       "3                    1               0            0  ...                  0   \n",
       "4                    0               0            0  ...                  0   \n",
       "...                ...             ...          ...  ...                ...   \n",
       "41114                0               0            0  ...                  0   \n",
       "41115                0               0            1  ...                  0   \n",
       "41116                0               0            0  ...                  0   \n",
       "41117                0               0            1  ...                  0   \n",
       "41118                1               0            0  ...                  1   \n",
       "\n",
       "       contact_unknown  month_aug  month_feb  month_jul  month_jun  month_may  \\\n",
       "0                    1          0          0          0          0          1   \n",
       "1                    1          0          0          0          0          1   \n",
       "2                    1          0          0          0          0          1   \n",
       "3                    1          0          0          0          0          1   \n",
       "4                    1          0          0          0          0          1   \n",
       "...                ...        ...        ...        ...        ...        ...   \n",
       "41114                0          0          0          0          0          0   \n",
       "41115                0          0          0          0          0          0   \n",
       "41116                0          0          0          0          0          0   \n",
       "41117                0          0          0          0          0          0   \n",
       "41118                0          0          0          0          0          0   \n",
       "\n",
       "       month_nov  poutcome_unknown  y_yes  \n",
       "0              0                 1      0  \n",
       "1              0                 1      0  \n",
       "2              0                 1      0  \n",
       "3              0                 1      0  \n",
       "4              0                 1      0  \n",
       "...          ...               ...    ...  \n",
       "41114          1                 1      1  \n",
       "41115          1                 0      1  \n",
       "41116          1                 1      1  \n",
       "41117          1                 1      1  \n",
       "41118          1                 1      0  \n",
       "\n",
       "[41119 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = 'banklimpio.csv'\n",
    "X_cleaned1 = pd.read_csv(file_path)\n",
    "X_cleaned1 = pd.read_csv(file_path, sep=',')  \n",
    "X_cleaned1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar Multicolinealidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poutcome_unknown 7.0537108370351165\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Añadir constante a X para calcular VIF\n",
    "X_with_const = sm.add_constant(X_cleaned1)\n",
    "\n",
    "# Calcular VIF para cada variable\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = X_with_const.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_with_const.values, i) for i in range(X_with_const.shape[1])]\n",
    "\n",
    "\n",
    "for i in range(1,len(vif_data)):\n",
    "    if vif_data[\"VIF\"][i]>5:\n",
    "        print(vif_data[\"Variable\"][i],vif_data[\"VIF\"][i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELO 1: VARIABLE DE RESPUESTA Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "X= X_cleaned1.drop(columns='y_yes')\n",
    "# Separar variables predictoras (X) y la variable objetivo (y)\n",
    "y = X_cleaned1['y_yes']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.24, random_state=1)\n",
    "\n",
    "# Crear y entrenar el modelo\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.15248625954163192\n",
      "MSE:  0.06555171655623256\n",
      "RMSE:  0.2560306945587434\n"
     ]
    }
   ],
   "source": [
    "# mean absolute error\n",
    "MAE = metrics.mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# mean squared error\n",
    "MSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# root mean squared error\n",
    "RMSE = np.sqrt(MSE)\n",
    "\n",
    "print(\"MAE: \", MAE)\n",
    "print(\"MSE: \", MSE)\n",
    "print(\"RMSE: \", RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE: 0.15487925416217363\n",
      "Mean MSE: 0.06655064153829034\n",
      "Mean RMSE: 0.21772616688069169\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# usar MSE - error cuadrático medio\n",
    "scores = cross_val_score(model, X, y, cv=100, scoring='neg_mean_squared_error')\n",
    "mse_scores = - scores\n",
    "scores = cross_val_score(model, X, y, cv=100, scoring='neg_mean_absolute_error')\n",
    "\n",
    "mae_scores = -scores\n",
    "\n",
    "#print(\"MAE scores for each fold:\", mae_scores)\n",
    "print(\"Mean MAE:\", np.mean(mae_scores))\n",
    "\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "\n",
    "print(\"Mean MSE:\", mse_scores.mean())\n",
    "print(\"Mean RMSE:\", rmse_scores.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELO 1: OLS VARIABLE DE RESPUESTA Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "y = X_cleaned1['y_yes']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "X_train = sm.add_constant(X_train)\n",
    "\n",
    "# Ajustar el modelo de regresión usando mínimos cuadrados ordinarios (OLS)\n",
    "md = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "# Resumen de resultados\n",
    "print(md.summary())\n",
    "\n",
    "# Extraer coeficientes y p-valores en un DataFrame\n",
    "results = pd.DataFrame({\n",
    "    'Variable': md.params.index,\n",
    "    'Coeficiente': md.params.values,\n",
    "    'p-valor': md.pvalues.values\n",
    "})\n",
    "# Filtrar variables significativas (usualmente p-valor < 0.01)\n",
    "significativas = results[results['p-valor'] < 0.1]\n",
    "no_significativas = results[results['p-valor'] >= 0.1]\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Variables Significativas (p-valor < 1%):\")\n",
    "print(significativas)\n",
    "\n",
    "print(\"\\nVariables No Significativas (p-valor >= 1%):\")\n",
    "print(no_significativas)\n",
    "no_significativas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELO 1: OLS SOLO CON VARIABLES SIGNIFICATIVAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_significativas = X_cleaned1[significativas['Variable'].values[1:]]  # [1:] para excluir 'const'\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train_significativas, X_test_significativas, y_train_significativas, y_test_significativas = train_test_split(X_significativas, y, random_state=1)\n",
    "\n",
    "# Agregar la constante para el modelo OLS\n",
    "X_train_significativas = sm.add_constant(X_train_significativas)\n",
    "X_test_significativas = sm.add_constant(X_test_significativas)\n",
    "\n",
    "# Ajustar el modelo OLS\n",
    "md_significativas = sm.OLS(y_train_significativas, X_train_significativas).fit()\n",
    "\n",
    "# Realizar predicciones sobre el conjunto de prueba\n",
    "y_pred_significativas = md_significativas.predict(X_test_significativas)\n",
    "\n",
    "# Calcular MAE, MSE y RMSE\n",
    "mae = mean_absolute_error(y_test_significativas, y_pred_significativas)\n",
    "mse = mean_squared_error(y_test_significativas, y_pred_significativas)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(md_significativas.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 2 logistico completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Separar variables predictoras (X) y la variable objetivo (y)\n",
    "X = X_cleaned1.drop(columns='y_yes')\n",
    "y = X_cleaned1['y_yes']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.24, random_state=1)\n",
    "\n",
    "# Crear y entrenar el modelo de regresión logística con scikit-learn\n",
    "model_logi = LogisticRegression(max_iter=1000)\n",
    "model_logi.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_predlog = model_logi.predict(X_test)\n",
    "\n",
    "# Calcular y mostrar métricas de clasificación\n",
    "accuracy = accuracy_score(y_test, y_predlog)\n",
    "precision = precision_score(y_test, y_predlog)\n",
    "recall = recall_score(y_test, y_predlog)\n",
    "f1 = f1_score(y_test, y_predlog)\n",
    "\n",
    "\n",
    "# Confusion matrix y reporte de clasificación\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_predlog))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_predlog,target_names=['No acepta', 'Acepta']))\n",
    "\n",
    "# Obtener un resumen detallado con statsmodels\n",
    "# Añadir una constante al conjunto de datos\n",
    "X_with_const = sm.add_constant(X)  # Asegúrate de incluir la constante para el modelo en statsmodels\n",
    "\n",
    "# Ajustar el modelo de regresión logística con statsmodels\n",
    "logit_model = sm.Logit(y, X_with_const)\n",
    "result = logit_model.fit()\n",
    "\n",
    "# Mostrar el resumen del modelo\n",
    "print(result.summary())\n",
    "\n",
    "# Convertir el índice en una columna llamada 'Variable'\n",
    "summary_df = pd.DataFrame({\n",
    "    'Variable': result.params.index,\n",
    "    'Coef': result.params,\n",
    "    'StdErr': result.bse,\n",
    "    'Z': result.tvalues,\n",
    "    'P>|Z|': result.pvalues,\n",
    "    'Conf. Interval Low': result.conf_int()[0],\n",
    "    'Conf. Interval High': result.conf_int()[1]\n",
    "}).reset_index()\n",
    "\n",
    "# Renombrar la columna que contiene el índice\n",
    "summary_df = summary_df.drop(columns=\"index\")\n",
    "\n",
    "# Mostrar el DataFrame con la columna 'Variable'\n",
    "summary_df\n",
    "\n",
    "# Filtrar variables significativas (usualmente p-valor < 0.01)\n",
    "significativaslog = results[results['p-valor'] < 0.1]\n",
    "no_significativaslog = results[results['p-valor'] >= 0.1]\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Variables Significativas (p-valor < 1%):\")\n",
    "print(significativaslog)\n",
    "\n",
    "print(\"\\nVariables No Significativas (p-valor >= 1%):\")\n",
    "print(no_significativas)\n",
    "no_significativaslog\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 2: Logistico significativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "# Seleccionar las variables significativas (excluyendo 'const')\n",
    "X_significativas = X_cleaned1[significativaslog['Variable'].values[1:]]  # [1:] para excluir 'const'\n",
    "y = X_cleaned1['y_yes']  # Asegúrate de que 'y_yes' sea la variable objetivo\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train_significativas, X_test_significativas, y_train_significativas, y_test_significativas = train_test_split(\n",
    "    X_significativas, y, random_state=1\n",
    ")\n",
    "\n",
    "# Agregar la constante para el modelo Logit\n",
    "X_train_significativas = sm.add_constant(X_train_significativas)\n",
    "X_test_significativas = sm.add_constant(X_test_significativas)\n",
    "\n",
    "# Ajustar el modelo de regresión logística\n",
    "md_significativas = sm.Logit(y_train_significativas, X_train_significativas).fit()\n",
    "\n",
    "# Realizar predicciones sobre el conjunto de prueba\n",
    "y_pred_proba = md_significativas.predict(X_test_significativas)\n",
    "\n",
    "# Convertir probabilidades a clases (0 o 1) usando un umbral de 0.5\n",
    "y_pred_significativas = [1 if prob >= 0.5 else 0 for prob in y_pred_proba]\n",
    "\n",
    "# Calcular métricas de clasificación\n",
    "accuracy = accuracy_score(y_test_significativas, y_pred_significativas)\n",
    "precision = precision_score(y_test_significativas, y_pred_significativas)\n",
    "recall = recall_score(y_test_significativas, y_pred_significativas)\n",
    "f1 = f1_score(y_test_significativas, y_pred_significativas)\n",
    "\n",
    "# Mostrar los resultados\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_significativas, y_pred_significativas))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_significativas, y_pred_significativas,target_names=['No acepta', 'Acepta']))\n",
    "\n",
    "# Mostrar el resumen del modelo logístico\n",
    "md_significativas.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Añadir constante a X para calcular VIF\n",
    "X_with_const = sm.add_constant(X_cleaned1)\n",
    "\n",
    "# Calcular VIF para cada variable\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = X_with_const.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_with_const.values, i) for i in range(X_with_const.shape[1])]\n",
    "\n",
    "\n",
    "for i in range(1,len(vif_data)):\n",
    "    if vif_data[\"VIF\"][i]>5:\n",
    "        print(vif_data[\"Variable\"][i],vif_data[\"VIF\"][i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Redes neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X_cleaned1.sample(frac=0.8, random_state=100)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = X_cleaned1.drop(train.index)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.setrecursionlimit(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las columnas categóricas y continuas\n",
    "categorical_features = []\n",
    "\n",
    "# Encontrar las columnas dummificadas\n",
    "for col in X_cleaned1.columns:\n",
    "    if \"_\" in col and col != \"y_yes\":  \n",
    "        categorical_features.append(col)\n",
    "\n",
    "\n",
    "continuous_features = [col for col in X_cleaned1.columns if col not in categorical_features and col != \"y_yes\"]\n",
    "\n",
    "# Mostrar las listas\n",
    "print(\"Categorical dummies:\", categorical_features)\n",
    "print(\"Continuous features:\", continuous_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_cleaned1.drop(columns=['y_yes'])\n",
    "\n",
    "# Definir la variable objetivo\n",
    "y = X_cleaned1['y_yes']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalización\n",
    "norm = tf.keras.layers.Normalization()\n",
    "norm.adapt(np.array(train_X))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "redes 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciar el cronómetro\n",
    "start_time = time.time()\n",
    "\n",
    "# Definir el modelo de red neuronal profunda con capas densas y Dropout\n",
    "linear_model_1 = tf.keras.Sequential([\n",
    "    norm,\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1)  # Capa de salida para regresión\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "linear_model_1.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    loss='mean_absolute_error',\n",
    "    metrics=['mae', 'mse']\n",
    ")\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "history_1 = linear_model_1.fit(\n",
    "    train_X,\n",
    "    train_y,\n",
    "    epochs=100,\n",
    "    validation_split=0.2,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Medir el tiempo de entrenamiento\n",
    "elapsed_time_1 = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redes 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciar el cronómetro\n",
    "start_time = time.time()\n",
    "\n",
    "# Definir el modelo de red neuronal profunda con capas densas y Dropout\n",
    "linear_model_2 = tf.keras.Sequential([\n",
    "    norm,\n",
    "    tf.keras.layers.Dense(units=128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dense(units=1)  # Capa de salida para regresión\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "linear_model_2.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mean_absolute_error',\n",
    "    metrics=['mae', 'mse']\n",
    ")\n",
    "\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "history_2 = linear_model_2.fit(\n",
    "    train_X,\n",
    "    train_y,\n",
    "    epochs=100,\n",
    "    validation_split=0.2,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Medir el tiempo de entrenamiento\n",
    "elapsed_time_2 = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar las métricas y la pérdida en subgráficas\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 15))\n",
    "\n",
    "# Pérdida (Loss)\n",
    "axs[0].plot(history_1.history['loss'], label='Pérdida de Entrenamiento', color='blue')\n",
    "axs[0].plot(history_1.history['val_loss'], label='Pérdida de Validación', color='orange', linestyle='--')\n",
    "axs[0].set_xlabel('Época')\n",
    "axs[0].set_ylabel('Pérdida (MAE)')\n",
    "axs[0].set_title(f'Modelo 1 - Pérdida (Tiempo: {elapsed_time_1:.2f} segundos)')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Error Cuadrático Medio (MSE)\n",
    "axs[1].plot(history_1.history['mse'], label='MSE de Entrenamiento', color='green')\n",
    "axs[1].plot(history_1.history['val_mse'], label='MSE de Validación', color='red', linestyle='--')\n",
    "axs[1].set_xlabel('Época')\n",
    "axs[1].set_ylabel('MSE')\n",
    "axs[1].set_title('Error Cuadrático Medio (MSE)')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Tiempo de entrenamiento del Modelo 1: {elapsed_time_1:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar las métricas y la pérdida en subgráficas\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 15))\n",
    "\n",
    "# Pérdida (Loss)\n",
    "axs[0].plot(history_2.history['loss'], label='Pérdida de Entrenamiento', color='blue')\n",
    "axs[0].plot(history_2.history['val_loss'], label='Pérdida de Validación', color='orange', linestyle='--')\n",
    "axs[0].set_xlabel('Época')\n",
    "axs[0].set_ylabel('Pérdida (MAE)')\n",
    "axs[0].set_title(f'Modelo 2 - Pérdida (Tiempo: {elapsed_time_2:.2f} segundos)')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Error Cuadrático Medio (MSE)\n",
    "axs[1].plot(history_2.history['mse'], label='MSE de Entrenamiento', color='green')\n",
    "axs[1].plot(history_2.history['val_mse'], label='MSE de Validación', color='red', linestyle='--')\n",
    "axs[1].set_xlabel('Época')\n",
    "axs[1].set_ylabel('MSE')\n",
    "axs[1].set_title('Error Cuadrático Medio (MSE)')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Tiempo de entrenamiento del Modelo 1: {elapsed_time_2:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Asegurarse de que test_X está en formato de numpy array con tipo float32\n",
    "test_X = np.array(test_X, dtype=np.float32)\n",
    "\n",
    "# Obtener los valores reales y las predicciones\n",
    "y_true = list(test_y)  # Convertir directamente a una lista de valores reales\n",
    "y_pred = []\n",
    "\n",
    "# Iterar sobre los datos de prueba para obtener las predicciones\n",
    "for x in test_X:\n",
    "    prediction = linear_model_1.predict(np.array([x]))  # Hacer predicción\n",
    "    y_pred.append(prediction.flatten()[0])  # Aplanar y agregar predicción\n",
    "\n",
    "# Convertir las predicciones a binario (0 o 1)\n",
    "y_pred_bin = [1 if pred >= 0.5 else 0 for pred in y_pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Calcular métricas\n",
    "print(classification_report(y_true, y_pred_bin, target_names=['No Aprobado', 'Aprobado']))\n",
    "print(\"Matriz de confusión:\\n\", confusion_matrix(y_true, y_pred_bin))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
