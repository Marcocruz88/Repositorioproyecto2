{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importación de librerías Requeridas\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path = 'bank-full.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df = pd.read_csv(file_path, sep=';')  \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELO 1: VARIABLE DE RESPUESTA PRODUCTIVIDAD ACTUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "X= X_cleaned1.drop(columns='y_yes')\n",
    "# Separar variables predictoras (X) y la variable objetivo (y)\n",
    "y = X_cleaned1['y_yes']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.24, random_state=1)\n",
    "\n",
    "# Crear y entrenar el modelo\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean absolute error\n",
    "MAE = metrics.mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# mean squared error\n",
    "MSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# root mean squared error\n",
    "RMSE = np.sqrt(MSE)\n",
    "\n",
    "print(\"MAE: \", MAE)\n",
    "print(\"MSE: \", MSE)\n",
    "print(\"RMSE: \", RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# usar MSE - error cuadrático medio\n",
    "scores = cross_val_score(model, X, y, cv=100, scoring='neg_mean_squared_error')\n",
    "mse_scores = - scores\n",
    "scores = cross_val_score(model, X, y, cv=100, scoring='neg_mean_absolute_error')\n",
    "\n",
    "mae_scores = -scores\n",
    "\n",
    "#print(\"MAE scores for each fold:\", mae_scores)\n",
    "print(\"Mean MAE:\", np.mean(mae_scores))\n",
    "\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "\n",
    "print(\"Mean RMSE:\", rmse_scores.mean())\n",
    "\n",
    "print(\"Mean MSE:\", mse_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELO 1: OLS VARIABLE DE RESPUESTA PRODUCTIVIDAD ACTUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "y = X_cleaned1['y_yes']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "X_train = sm.add_constant(X_train)\n",
    "\n",
    "# Ajustar el modelo de regresión usando mínimos cuadrados ordinarios (OLS)\n",
    "md = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "# Resumen de resultados\n",
    "print(md.summary())\n",
    "\n",
    "# Extraer coeficientes y p-valores en un DataFrame\n",
    "results = pd.DataFrame({\n",
    "    'Variable': md.params.index,\n",
    "    'Coeficiente': md.params.values,\n",
    "    'p-valor': md.pvalues.values\n",
    "})\n",
    "# Filtrar variables significativas (usualmente p-valor < 0.01)\n",
    "significativas = results[results['p-valor'] < 0.1]\n",
    "no_significativas = results[results['p-valor'] >= 0.1]\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Variables Significativas (p-valor < 1%):\")\n",
    "print(significativas)\n",
    "\n",
    "print(\"\\nVariables No Significativas (p-valor >= 1%):\")\n",
    "print(no_significativas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELO 1: OLS SOLO CON VARIABLES SIGNIFICATIVAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_significativas = X_cleaned1[significativas['Variable'].values[1:]]  # [1:] para excluir 'const'\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train_significativas, X_test_significativas, y_train_significativas, y_test_significativas = train_test_split(X_significativas, y, random_state=1)\n",
    "\n",
    "# Agregar la constante para el modelo OLS\n",
    "X_train_significativas = sm.add_constant(X_train_significativas)\n",
    "X_test_significativas = sm.add_constant(X_test_significativas)\n",
    "\n",
    "# Ajustar el modelo OLS\n",
    "md_significativas = sm.OLS(y_train_significativas, X_train_significativas).fit()\n",
    "\n",
    "# Realizar predicciones sobre el conjunto de prueba\n",
    "y_pred_significativas = md_significativas.predict(X_test_significativas)\n",
    "\n",
    "# Calcular MAE, MSE y RMSE\n",
    "mae = mean_absolute_error(y_test_significativas, y_pred_significativas)\n",
    "mse = mean_squared_error(y_test_significativas, y_pred_significativas)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(md_significativas.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo Redes neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X_cleaned1.sample(frac=0.8, random_state=100)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = X_cleaned1.drop(train.index)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.setrecursionlimit(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las columnas categóricas y continuas\n",
    "categorical_features = []\n",
    "\n",
    "# Encontrar las columnas dummificadas\n",
    "for col in X_cleaned1.columns:\n",
    "    if \"_\" in col and col != \"y_yes\":  \n",
    "        categorical_features.append(col)\n",
    "\n",
    "\n",
    "continuous_features = [col for col in X_cleaned1.columns if col not in categorical_features and col != \"y_yes\"]\n",
    "\n",
    "# Mostrar las listas\n",
    "print(\"Categorical dummies:\", categorical_features)\n",
    "print(\"Continuous features:\", continuous_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_cleaned1.drop(columns=['y_yes'])\n",
    "\n",
    "# Definir la variable objetivo\n",
    "y = X_cleaned1['y_yes']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalización\n",
    "norm = tf.keras.layers.Normalization()\n",
    "norm.adapt(np.array(train_X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciar el cronómetro\n",
    "start_time = time.time()\n",
    "\n",
    "# Definir el modelo de red neuronal profunda con capas densas y Dropout\n",
    "linear_model_1 = tf.keras.Sequential([\n",
    "    norm,\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1)  # Capa de salida para regresión\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "linear_model_1.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    loss='mean_absolute_error',\n",
    "    metrics=['mae', 'mse']\n",
    ")\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "history_1 = linear_model_1.fit(\n",
    "    train_X,\n",
    "    train_y,\n",
    "    epochs=100,\n",
    "    validation_split=0.2,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Medir el tiempo de entrenamiento\n",
    "elapsed_time_1 = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar las métricas y la pérdida en subgráficas\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 15))\n",
    "\n",
    "# Pérdida (Loss)\n",
    "axs[0].plot(history_1.history['loss'], label='Pérdida de Entrenamiento', color='blue')\n",
    "axs[0].plot(history_1.history['val_loss'], label='Pérdida de Validación', color='orange', linestyle='--')\n",
    "axs[0].set_xlabel('Época')\n",
    "axs[0].set_ylabel('Pérdida (MAE)')\n",
    "axs[0].set_title(f'Modelo 1 - Pérdida (Tiempo: {elapsed_time_1:.2f} segundos)')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Error Cuadrático Medio (MSE)\n",
    "axs[1].plot(history_1.history['mse'], label='MSE de Entrenamiento', color='green')\n",
    "axs[1].plot(history_1.history['val_mse'], label='MSE de Validación', color='red', linestyle='--')\n",
    "axs[1].set_xlabel('Época')\n",
    "axs[1].set_ylabel('MSE')\n",
    "axs[1].set_title('Error Cuadrático Medio (MSE)')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Tiempo de entrenamiento del Modelo 1: {elapsed_time_1:.2f} segundos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
